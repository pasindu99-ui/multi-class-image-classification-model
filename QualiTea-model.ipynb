{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "tf = pd.read_csv('/content/gdrive/MyDrive/THE OUTLAWS - SDGP/details1.csv') \n",
    "tt = pd.read_csv('/content/gdrive/MyDrive/THE OUTLAWS - SDGP/Testdetails.csv') \n",
    "tf.head()\n",
    "\n",
    "# train_dataset_path = '/kaggle/input/intel-image-classification/seg_train/seg_train/'\n",
    "# validation_dataset_path = '/kaggle/input/intel-image-classification/seg_test/seg_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                  zoom_range=0.2,\n",
    "                                  width_shift_range=0.2,\n",
    "                                 height_shift_range=0.2,\n",
    "                                  fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                  zoom_range=0.2,\n",
    "                                  width_shift_range=0.2,\n",
    "                                 height_shift_range=0.2,\n",
    "                                  fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(dataframe=tt,directory=\"/content/gdrive/MyDrive/THE OUTLAWS - SDGP/Test\",\n",
    "                                                              x_col=\"Name\", y_col=\"category\",target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "                                                             batch_size=BATCH_SIZE,\n",
    "                                                             class_mode='categorical',\n",
    "                                                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {value: key for key, value in train_generator.class_indices.items()}\n",
    "\n",
    "print(\"Label Mappings for classes present in the training and validation datasets\\n\")\n",
    "for key, value in labels.items():\n",
    "    print(f\"{key} : {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(15, 12))\n",
    "idx = 0\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        label = labels[np.argmax(train_generator[0][1][idx])]\n",
    "        ax[i, j].set_title(f\"{label}\")\n",
    "        ax[i, j].imshow(train_generator[0][0][idx][:, :, :])\n",
    "        ax[i, j].axis(\"off\")\n",
    "        idx += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Sample Training Images\", fontsize=21)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(filters=128, kernel_size=(5, 5), padding='valid', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Conv2D(filters=64, kernel_size=(3, 3), padding='valid', kernel_regularizer=l2(0.00005)),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Conv2D(filters=32, kernel_size=(3, 3), padding='valid', kernel_regularizer=l2(0.00005)),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Flatten(),\n",
    "        \n",
    "        Dense(units=256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(units=6, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer=optimizer, loss=CategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn_model.fit(train_generator, epochs=100, validation_data=validation_generator,verbose=2,callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "learning_rate = history.history['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(12, 10))\n",
    "\n",
    "ax[0].set_title('Training Accuracy vs. Epochs')\n",
    "ax[0].plot(train_accuracy, 'o-', label='Train Accuracy')\n",
    "ax[0].plot(val_accuracy, 'o-', label='Validation Accuracy')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].legend(loc='best')\n",
    "\n",
    "ax[1].set_title('Training/Validation Loss vs. Epochs')\n",
    "ax[1].plot(train_loss, 'o-', label='Train Loss')\n",
    "ax[1].plot(val_loss, 'o-', label='Validation Loss')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend(loc='best')\n",
    "\n",
    "ax[2].set_title('Learning Rate vs. Epochs')\n",
    "ax[2].plot(learning_rate, 'o-', label='Learning Rate')\n",
    "ax[2].set_xlabel('Epochs')\n",
    "ax[2].set_ylabel('Loss')\n",
    "ax[2].legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save(\"model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = \"/content/20211010_052018743_iOS.heic\"\n",
    " \n",
    "img = cv2.imread(test_img_path)\n",
    "resized_img = cv2.resize(img, (150, 150)).reshape(-1, 150, 150, 3)/255\n",
    "\n",
    "\n",
    "# check prediction\n",
    "pred = cnn_model.predict(resized_img)\n",
    "output = { 0:'low withered poor',1:'low withered best',2:'low withered below best',3:'low fresh poor',4:'low fresh best',5:'low fresh below best'}\n",
    "\n",
    "print(pred)\n",
    "print(\"Predicted :- \",output[np.argmax(pred)])\n",
    " \n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"TEST IMAGE\")\n",
    "plt.imshow(resized_img[0])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
